
\documentclass{article}
\usepackage[margin=1.5in]{geometry}
%\usepackage{fullpage}
%\usepackage{setspace}
%\doublespacing
\linespread{2}
\usepackage{cite}

\usepackage[pdftex]{graphicx}
% declare the path(s) where your graphic files are
\graphicspath{{./images/}}
 % and their extensions so you won't have to specify these with
 % every instance of \includegraphics
 \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
%\usepackage{fancyhdr}

\usepackage{threeparttable}

\usepackage{enumerate}

%\usepackage{tgbonum}
%\usepackage{ascii}
%\usepackage[T1]{fontenc}

\begin{document}

\linespread{1}
\title{Integrating pattern matching\\
within string scanning}
\author{John H. Goettsche\\
  Dept.\ of Computer Science\\
  University of Idaho}

\maketitle

\begin{abstract}
A SNOBOL4 like pattern data type and pattern matching operation were introduced to the Unicon language in 2005, but patterns were not integrated with the Unicon string scanning control structure at that time.  The goal of this project is to make the pattern data type accessible to the Unicon string scanning and vice versa.  Also make the pattern operators and functions lexically consistent with Unicon.  To accomplish these goals, a Unicon tabmat operator was changed to allow the execution of a pattern match in the anchored mode, pattern matching unevaluated expressions were revised to handle complex string scanning functions, and the pattern matching lexeme was revised to be more consistent with the Unicon language.

\end{abstract}

\pagebreak
\linespread{1}
\tableofcontents

\pagebreak
\section{Introduction}
In order to enhance programmers' productivity in analyzing strings, many different string scanning and pattern matching systems have been developed.  Modern highlevel languages tend to offer regular expressions and context free grammars for their string processing.  Analysis of strings often requires functionality beyond what these classes of languages offer.  SNOBOL4 was the most successful of the early string processing languages. \cite{Snobol, Gaikaiwari2005}  A pattern data type was employed in SNOBOL4 along with pattern operators and functions to perform the analysis.

A successor to SNOBOL4 was Icon, which expanded upon the goal directed evaluation with generators and backtracking that was implicit in SNOBOL4's pattern matching.\cite{GriswoldIcon, Gaikaiwari2005}  It uses a string scanning control structure that passes through the subject string with a set of commands to manipulate and analyze its contents.  Many of the Unicon string scanning functions resemble SNOBOL4 patterns, but they are different in both how they are processed as well as their functionality.  Many Icon programmers have expressed a desire for the functionality of SNOBOL4 patterns.\cite{Griswold1980}.

When Unicon was developed, its core elements came directly from Icon, including its string scanning facilities.\cite{JefferyUnicon}  While SNOBOL patterns are instances of a structured data type that are used deductively to test whether the pattern exists within a subject string, the string scanning environment uses a set of functions to inductively analyze or extract data from the subject string.  Patterns are pre-defined and applied later, while string scanning is performed as string scanning functions are executed.  Patterns allow composition and re-use in more flexible ways than is the case for code, which only has procedure and co-expression granularity.

This paper briefly explores the background of SNOBOL4 patterns and Unicon string scanning functions.  It discusses design considerations for integrating SNOBOL4 patterns within Unicon string scanning environments, a description of how proposed changes where implemented, and the benchmarks used to evaluate the success of the integration.

\section{Background}
SNOBOL was developed by David Farber, Ralph Griswold and Ivan Polonsky at Bell Telephone Laboratories in 1962.  SNOBOL4 was developed in 1967 and had many of the features that are included in popular dynamic programming languages including dynamic typing, eval and garbage collection.  Its pattern data type was its most important contribution to string processing.  Patterns could be as simple as a single character or a set of characters in a particular order, or they could be a complex arrangement with alternative character sets and pattern functions.  The pattern data type enabled the user to define and store patterns as variables to be used later when they were desired.\cite{Snobol}  

One of the developers of SNOBOL4, Ralph Griswold, went to the University of Arizona and developed the Icon programming language which was more readable and simpler to use.\cite{JefferyUnicon}  Griswold used his experience with SNOBOL4's generators and backtracking in its pattern matching to develop and implement goal directed evaluation.\cite{Gaikaiwari2005}  SNOBOL4 patterns were not incorporated in Icon.  Instead Griswold developed an extensive string scanning system where a variety of functions and operations are executed in order to analyze and manipulate a subject string as a cursor advances through the subject string.  Unlike most other languages, Icon considers the string as a data type in its own right, rather than an array of characters. \cite{GriswoldIcon}  

Using the same Icon source code, Unicon was developed to include modern software features such as objects, networks and databases. \cite{JefferyUnicon} The string scanning control structure of Icon is a part of the Unicon programming language, yet the desire of researchers and developers for SNOBOL4's pattern data structure and pattern matching environment has persisted.  Sudarshan Gaikaiwari adopted SNOBOL4 patterns to the Unicon language for his master's thesis in 2005.  In his thesis, he added the pattern data type, and provided pattern matching functions and operators to execute the pattern searches.\cite{Gaikaiwari2005}  The pattern data type was kept separate from the string scanning environment, which may not execute pattern matching operations.  This paper refines Gaikaiwari's work to be more naturally incorporated in the Unicon language, allowing string scanning environments to utilize the pattern matching functionality and vice-versa.

\section{Design Considerations}
To integrate pattern matching with Unicon string scanning required consideration of how a user would execute a pattern match in the string scanning environment and a string scanning functions in the pattern matching operation.  What parameters are necessary for their execution given the environment from which they are being called and how they are going to be utilized and under what conditions for each implementation.  The pattern functions and operators will have to be consistent lexically and functionally with the Unicon language.

\subsection{Pattern matching statements}
SNOBOL pattern matching can be executed in either anchored or non-anchored mode.  The anchored mode requires the match to start on the first character of the subject string while in the non-anchored mode the match can start at any location in the subject string.\cite{Snobol}  The pattern matching operation adapted by Gaikaiwari are generators and operate in the non-anchored mode.\cite{Gaikaiwari2005}  They only produce one value at a time, but since they suspend instead of return that value, the cursor position is stored so the next pattern can be applied to the remainder of the string to produce the next value. \cite{JefferyUnicon}

The pattern matching statements in SNOBOL4 and Gaikaiwari's Unicon implementation are in the following from:\\

\begin{table}[ht]
	\centering
	\begin{tabular}{c c}
		SNOBOL4 & Gaikaiwari's Unicon \\
		\texttt{ SUBJECT  PATTERN }& 
		
		\texttt{ subject ?? pattern }

	\end{tabular}
\end{table}
\noindent
In both examples, the subject is scanned to see if it contains the pattern.  If it succeeds, then a substring of the subject that fits the pattern is produced.  Gaikaiwari's syntax starts the pattern matching operation with the use of the \texttt{??} operator while SNOBOL4 uses two spaces between the subject and pattern.  Since the Unicon string scanning operator is \texttt{?} and used in the following syntax:
\begin{verbatim}
   subject ? expr
\end{verbatim}
Gaikaiwari's operator in the following syntax:
\begin{verbatim}
   subject ?? pattern
\end{verbatim}
is a better match to Unicon lexically and syntactically, and is easier to read than separating the subject and pattern with white space.   

To integrate pattern matching into the Unicon language, it is necessary to consider which mode is appropriate considering the current environment.  If it is being executed outside of a Unicon string scanning environment, the cursor position or index of the string has not been established.  Therefore the non-anchored mode would be appropriate for basic pattern matching operations.  This allows the a pattern to be matched anywhere within the subject string.  

In the anchored mode the pattern match begins at the current cursor or index location, if the pattern fails at the first character then the entire pattern will fail to match and will not look for an alternate match later in the subject string.  Sometimes the user wishes to start the pattern match at the first location in the subject string, as though it was in the anchored mode.  In these situations the pattern can be defined with \texttt{Pos(1)} as the first element in the pattern definition, will have the desired effect.

\subsubsection{Pattern matching within String Scanning}
In the Unicon string scanning environment the functions operate in relation to the cursor position of the subject string.  It is an inductive process where the data is analyzed by injecting the functions into the subject string.  The cursor location or index is adjusted depending on the success or failure of each expression.  When executing pattern matching from within a Unicon string scanning environment, the cursor or index location is established.  Therefore, in order to maintain this indexing process in the string scanning environment, it was decided to execute the pattern matching operation in the anchored mode.  

Unicon's \texttt{?} operator sets the cursor location to the first position in the subject string and the function or the block of functions that are called in the expression are executed.  Scanning functions normally move the cursor upon success, for this reason, it was decided, in the event that a pattern is encountered with the tabmat \texttt{=} operator, the pattern match is performed in the anchored mode, with the cursor being advanced to the end of the matching pattern if there is success.

\subsubsection{String Scanning within Patterns}
Patterns are pre-defined and are used deductively to search a subject string for the pattern.  A regular pattern match is performed in the un-anchored mode and establishes the cursor locations for the beginning and end of a pattern when it is found.  This is done by iterating through the subject string until a match is found.  It is possible for a string scanning function to be performed as the the pattern matching process iterates through the cursor or index locations.

According Gaikaiwari's thesis, his pattern matching environment allows simple single depth function calls to be made with an unevaluated expression.  His unevaluated expressions can handle function call such as \texttt{`foo(2 , "bar")} but can not handle function calls from within function calls like \texttt{tab(upto(somecset))}.\cite{Gaikaiwari2005}  Therefore revising the unevaluated expressions to handle more complex functions calls which are common when performing string scanning operations.

\subsection{SNOBOL4 and Unicon pattern operators}
The pattern operators for Unicon were defined by Gaikaiwari in his Master's Thesis.  Although they are lexically different, they are functionally identical to SNOBOL4 pattern operators.  Gaikaiwari's operators for concatenation and alternation are lexically different from Unicon concatenation and alternation and the assignment operators are lexically inconsistent.  

\begin{table}[ht]
	\caption{Pattern Operators}
	\centering
	\begin{tabular}{|l|l|l|l|}
		\hline\hline
		Operation & SNOBOL4 & Gaikaiwari & New\\
		\hline
		Concatenation & $<<$implicit$>>$ & \&\& & $||$ \\
		Alternation & $|$ & $.|$ & $.|$ \\
		\hline
		Immediate Assignment & \$ & \$\$ & $=>$ \\
		Conditional Assignment & . & $->$ & $->$\\
		Cursor Assignment & @ & .\$ & .$>$ \\
		\hline
		Unevaluated Expression & $*$x & `x` & `x` \\
		\hline
	\end{tabular}
\end{table}
The Unicon operator for string concatenation was modified to recognize whether the expression contains a pattern.  Since the pattern concatenation and Unicon's string concatenation operators do not have the same order of presidents, this resulted in a semantic change in writing pattern definitions with assignment operators.  The value assignments must occure at the end of a sub-pattern.  If the pattern definition has additional sub-patterns then parentheses will be required to seperate the assignment from the rest of the pattern.  For example with \texttt{pattern := (Pos(4) $||$ Len(3) => pre) $||$ Span(\&digits)}, \texttt{pre} will be defined from the sub-pattern \texttt{Pos(4) $||$ Len(3)}.  The cursor assignments has not changed in that it must be separated from the pattern functions and unevaluated expressions with either a concatenation or an alternation.

The assignment operators were changed lexically to use the \texttt{$>$} symbol to represent an assignment within patterns.  The Immediate Assignment, Conditional Assignment and Cursor assignment are \texttt{$=>$}, \texttt{$->$} and \texttt{.$>$} respectively.

\vspace{1 pc}
\subsection{SNOBOL4 and Unicon pattern functions}
Since the demand for SNOBOL4 patterns to be added to Unicon is comming from SNOBOL4 users, it is important that the Unicon pattern functions appear lexically similar to SNOBOL4 pattern functions as possible, while being lexically consistant with Unicon.  Gaikaiwari's pattern functions 
are functionally the same as SNOBOL4 patterns, but appear somewhat disconnected from Unicon lexically.  The way in which Unicon handles its csets and strings makes some functions redundant or inconsistent with Unicon, therefore some of the pattern functions will be removed. 

The table below shows the SNOBOL4 primitive functions and the new Unicon pattern functions.  In most cases, the function is lexically similar to SNOBOL4 with the first character being capitalized and the following letters in lower-case, with exceptions for FAIL and ABORT.  Other changes are described in the example uses of the functions below: 

\begin{table}[ht]
	\begin{threeparttable}
		\caption{Pattern Functions}
		\centering
		\begin{tabular}{|l|l|l|}
			\hline\hline
			SNOBOL4 & Gaikaiwari & New \\
			\hline
			LEN(n) & PLen(n) & Len(n) \\
			SPAN(c) & PSpan(c) & Span(c)  \\
			BREAK(c) & PBreak(c) & Break(c) \\
			ANY(c) & PAny & Any(c)* \\
			NOTANY(c) & PNotAny(c) &  \\
			TAB(n) & PTab(n) & Tab(n)** \\
			RTAB(n) & PRtab(n) &  \\
			REM & PRest() & Rem() \\
			POS(n) & PPos(n) & Pos(n)**  \\
			RPOS(n) & PRpos(n) &  \\
			FAIL & PFail() & Back()*** \\
			FENCE & PFence() & Fence() \\
			ABORT & PAbort() & Cancel()*** \\
			ARB & PArb() & Arb() \\
			ARBNO(p) & PArbno(p) & Arbno(p) \\
			BAL & PBal() & Bal() \\
			\hline
		\end{tabular}
		
		\begin{tablenotes}
      		\small
      		\item * see logically redundant functions described in subsection 3.3.1 below
      		\item ** see index related functions described in subsection 3.3.2 below
      		\item *** see backtracking and terminating functions in subsection 3.3.3 below
      	\end{tablenotes}
	\end{threeparttable}
\end{table}


\vspace{1 pc}
\subsubsection{Complements with functions}
The complement operator allows the user to get the complement of a given cset, or a cset containing all the characters not included in the given cset.  Therefore the functionality of \texttt{NotAny(c)} function can be achieved by using the complement operator with a cset in the Any function as \texttt{Any($\sim$c)}.  The run time for each method is the same on average.

\vspace{1 pc}
\subsubsection{Index Related Functions}
\texttt{POS(n)}, \texttt{RPOS(n)}, \texttt{TAB(n)} and \texttt{RTAB(n)} SNOBOL4 functions all work directly with the cursor location or index.  In Unicon the index value is the number of spaces to the right from the left end of string with the first position being 1 or starting at the right end of the string starting with zero and subtracting the number of spaces to the right end of the string.\cite{JefferyUnicon}   The illustration below demonstrates the Unicon cursor position values for the string "Unicon" with the vertical bars representing the index locations:

\begin{verbatim}
                   -6  -5  -4  -3  -2  -1  0
                   | U | n | i | c | o | n |
                   1   2   3   4   5   6   7
\end{verbatim}

The SNOBOL4 cursor locations for the \texttt{RPOS(n)} and \texttt{RTAB(n)} functions the cursor locations are as follows:

\begin{verbatim}
   RPOS(n) & RTAB(n)    6   5   4   3   2   1   0
                        | S | N | O | B | O | L |
   POS(n) & TAB(n)      1   2   3   4   5   6   7
\end{verbatim}

Integration of the SNOBOL4 \texttt{RPOS(n)} and \texttt{RTAB(n)} functions with the Unicon string indexes can be achieved with \texttt{Pos(-n)} and \texttt{Tab(-n)} functions, making \texttt{RPOS(n)} and \texttt{RTAB(n)} redundant.

\vspace{1 pc}
\subsubsection{Backtracking and Terminating Functions}
Fail is already taken as a keyword in Unicon.  Attempts to use this name created a lot problems in compiling Unicon.  Fail in Unicon means that there is not a successful result in the operation.  While performing the pattern matching operation, \texttt{FAIL} is used to signify that there is not a successful result in the current pattern element and instructs the system to backtrack and to try another alternative.  Since the function is localized to a pattern match element and is not intended for a failure of the entire operation, it makes sense to use \texttt{Back()} for the SNOBOL4 \texttt{FAIL} function.


Likewise \texttt{ABORT} is a SNOBOL function that cancels the pattern matching operation, but does not halt the operation of the entire program.  \texttt{Cancel()} would be a more appropriate term for the \texttt{ABORT} function.

\section{Implementation}
To implement these changes the following changes to the Unicon language had to be made:
\begin{itemize}
\item Modify Unicon's runtime to execute pattern matching in the anchored mode when a pattern operand is used with the tabmat operator in a string scanning environment.
\item Modify the unevaluated expression operand in the pattern matching operation to handle function calls as a parameter in string scanning function calls.
\item Modify the pattern source files to address the functional changes for \texttt{Pos(n)} and \texttt{Tab(n)}.
\item Modify function definitions for the Unicon build.
\item Modify the concatenation operator to function with patterns.
\end{itemize}

\subsection{Pattern matching statements}
The non-anchored pattern matching operation was implemented by Sudarshan Gaikaiwari in his 2005 Master's thesis at New Mexico State University.  A non-anchored pattern matching expression consists of a subject followed by the comparison operator \texttt{??} followed by a pattern and appears as follows:

\begin{verbatim}
   subject ?? pattern
\end{verbatim}

The anchored pattern matching operation was defined in the pattern resources as a part of the internal match function, but the Anchored\_Mode identifier was set to false.  The default location of the index was set to 1.  The arguments for the internal match were changed so the mode would be passed in along with the current index.  This allows the internal match to be called and initiated in the proper location of the subject string.

\subsubsection{Anchored mode from string scanning}
It was decided that integrating the pattern matching system into the Unicon string scanning environment would require the pattern matching be performed in the anchored mode, since the string scanning functions are dependent upon the index or cursor position.  For this implementation the Unicon tabmat operator \texttt{=} was determined to be an ideal choice for initiating a pattern match in the string scanning environment.  The use of an equals \texttt{=} before a pattern variable triggers the anchored mode pattern matching operation.
 
\begin{verbatim}
   subjectString ? {
      match := =pattern
   }
\end{verbatim}

The tabmat operator was modified to accept pattern data types.  In the event that a pattern was its argument then it initiates a pattern match in the anchored mode, otherwise it functions normally.  This section of code identifies whether the argument is a pattern or a string and assigns its return value, and performs the assignments required for the pattern match.

\begin{verbatim}
   if is:pattern(x) then {
      abstract {
         return string
         }
      body {
         int oldpos;
         int start;
         int stop;
         struct b_pattern *pattern = NULL;
         tended struct b_pelem *phead = NULL; 
         char * pattern_subject;
         int subject_len;
         int new_len;
         CURTSTATE();
         
         /*
          * set cursor position, and subject to match
          */
         oldpos = k_pos;
         pattern_subject = StrLoc(k_subject);
         subject_len = StrLen(k_subject);
         pattern = (struct b_pattern *)BlkD(x, Pattern);
         phead = (struct b_pelem *)ResolvePattern(pattern);
         
         /*
          * runs a pattern match in the Anchored Mode and returns
          * a sub-string if it succeeds.
          */
         if (internal_match(pattern_subject, subject_len, pattern->stck_size,
               phead, &start, &stop, k_pos - 1, 1)){
            /*
             * Set new &pos.
             */ 
            k_pos = stop + 1;
            EVVal(k_pos, E_Spos);	
            oldpos = k_pos;
         
            /*
             * Suspend sub-string that matches pattern.
             */
            suspend string(stop - start, StrLoc(k_subject)+ start);
            pattern_subject = StrLoc(k_subject);
            if (subject_len != StrLen(k_subject)) {
               k_pos += StrLen(k_subject) - subject_len;
               subject_len = StrLen(k_subject);
               }
            }
            
         /*
          * If tab is resumed, restore the old position and fail.
          */
         if (oldpos > StrLen(k_subject) + 1){
            runerr(205, kywd_pos);
            } 
         else {
            k_pos = oldpos;
            EVVal(k_pos, E_Spos);
            }
         fail;
         }
      }
\end{verbatim}

As shown above, the assignment of parameter values for the \texttt{internal\_match} is required. The index or cursor location had to be assigned so that the anchored pattern match would begin where the string scanning had left off.  Finally, if the pattern was successful, then it would have to suspend the matching pattern update the index or cursor locations, if it failed then it would revert to the previous index.  The following code was added to the body of the tabmat operator:

\subsubsection{String Scanning Functions as Unevaluated Expressions}
In Sudarshan Gaikaiwari's implementation of SNOBOL4 patterns in Unicon, functions can be called in a pattern using the unevaluated expression notation by placing the function call in back quotes, for example: \texttt{pattern := `tab(3)`}.  This allows the user to assign simple Unicon string scanning function calls and procedure calls in the pattern definition. 

The first phase of the analysis an unevaluated expression occurs during compile time.  In this process The \texttt{process\_uneval} procedure is called where \texttt{emit\_code\_for\_uneval} procedure is invoked to generates a list to be interpreted during runtime.  Both of these procedures are found in the tree.icn file of the Unicon implementation.
\begin{verbatim}
procedure emit_code_for_uneval(funcname)
   L := []
   tab(many("`"))
   temp := tab(upto("(.")) 
   if \temp == "\\" then temp := "\\\\"
   put(L,\temp)
   while tab(upto(&letters)) do {
      temp := tab(many(&letters))
      put(L,temp)
      }
   writes(yyout,funcname, "(")
   writes(yyout, "[")
   every temp := !L\ (*L -1) do {
      writes(yyout, "\"", temp,"\",")
      }
   writes(yyout, "\"", L[*L], "\"")
   writes(yyout, "])")
   return
end
\end{verbatim}
The list generated in this process is similar to LISP in that the first element is the function to be called and the remaining elements are the parameters.  Unfortuneately, Gaikaiwari's implementation could not handle functions or procedure calls as parameters within another function or procedure call as is common with some string scanning functions.  For example \texttt{tab(upto('e'))}.  In this example the tab function requires an integer value which is acquired by the upto function that scans a string until it reaches an 'e' character.  His procedure would generate a list \texttt{["tab", "upto", "e"]}, where \texttt{upto} would not be a function call, but instead treated as a string.  This procedure had to be revised to handle function calls as parameters in a function call.  It was decided that a recursive procedure generating the list for each function that is used as a parameter in the parent function.  It was implemented with the following two procedures: 
\begin{verbatim}
procedure writes_code_for_uneval(L)
   writes(yyout, "[")
   every temp := !L\ (*L -1) do {
      if type(temp) == "list" then {
         writes_code_for_uneval(temp)
         } 
      else {
         writes(yyout, "\"", temp,"\",")
         }
      }
   if type(L[*L]) == "list" then {
      writes_code_for_uneval(L[*L])
      }
   else {
      writes(yyout, "\"", L[*L], "\"")
      }
   writes(yyout, "]")
   return
end

procedure emit_code_for_uneval(funcname)
   L := []
   tab(many("`"))
   temp := tab(upto("(.")) 
   if \temp == "\\" then temp := "\\\\"
   put(L, \temp)
   List := L
   while tab(upto(&letters ++ &digits ++ '\'\"&')) do {
      temp := tab(many(&letters ++ &digits ++ '\'\"&'))
      if proc(temp) then {
         L1 := []
         put(L1, temp)
         put(List, L1)
         List := L1
         } 
      else {
         put(List, temp)
         }
      }
   writes(yyout, funcname, "(")
   writes_code_for_uneval(L)
   writes(yyout, ")")
   return
end
\end{verbatim}
It was also decided that variables, strings and csets be differentiated by including double quotes around strings and single quotes around csets, and no quotes for variables.  In this case, when a the string scanning function \texttt{tab(upto('e'))} is called, it will generate the list: \texttt{["tab", ["upto", "'e'"]]}, which then can be interpreted with a list with the function "tab" along with a parameter containing a list with the function "upto" with the parameter being the cset 'e'.

To evaluate this list of lists during runtime a ResolveList function was added to the fxpattrn.ri file in the Unicon runtime implementation.  
\begin{verbatim}
struct b_list *ResolveList(struct b_list *lp)
{
   struct descrip proc;
   struct descrip var;
   tended struct b_lelem *elsrc;
   int i, nargs;
   tended struct b_list *lpsrc;
   tended struct b_list *lpdest;
   struct b_list *lptemp;
   tended char *temp;
   lpsrc = lp;
   lpdest = alclist(lpsrc->size,lpsrc->size);
   DEBUGF(20,(stdout, "Resolving function name and parameters"));
   nargs = lpsrc->size -1;
   elsrc = (struct b_lelem *)lpsrc->listhead;
   proc.dword = D_Proc;
   BlkLoc(proc)= (union block *)strprc(&elsrc->lslots[0],nargs);
   if (BlkLoc(proc) == NULL) {
      fprintf(stdout, "Unable to find proc");
      fatalerr(0, NULL);
      }
   for (; BlkType(elsrc) == T_Lelem; elsrc = (struct b_lelem *)elsrc->listnext) {
      for (i = 1; i < elsrc->nused; i++) {
         tended char * varname;
         struct descrip parm;
         dptr pvar;
         if (is:string(elsrc->lslots[i])) {
            cnv:C_string(elsrc->lslots[i], varname);
            if (StrLen(elsrc->lslots[i])>0) {
               if (strcspn(varname, "\'") == 0) { 
                  /* drop the quotes, but pass string as a cset */
                  StrLoc(elsrc->lslots[i]) = StrLoc(elsrc->lslots[i]) + 1;
                  StrLen(elsrc->lslots[i]) = StrLen(elsrc->lslots[i]) - 2;
                  cnv:cset(elsrc->lslots[i], elsrc->lslots[i]);
                  parm = elsrc->lslots[i];
                  }
               else if (strcspn(varname, "\"") == 0) {
                  /* drop the quotes, but pass string as a cset */
                  StrLoc(elsrc->lslots[i]) = StrLoc(elsrc->lslots[i]) + 1;
                  StrLen(elsrc->lslots[i]) = StrLen(elsrc->lslots[i]) - 2;
                  cnv:string(elsrc->lslots[i], elsrc->lslots[i]);
                  parm = elsrc->lslots[i];
                  }
               else if (strcspn(varname, "&") == 0) {
                  if ( getkeyword(varname, &parm) == Failed) {
                     VariableLookupFailed(varname);
                     }
                  elsrc->lslots[i] = parm;
                  }
               else {
                  if ( getvar(varname, &parm) == Failed) {
                     VariableLookupFailed(varname);
                     }
                  pvar = VarLoc(parm);
                  elsrc->lslots[i] = *pvar;
                  }
               }
            }
         else if (is:list(elsrc->lslots[i])) {
            /* recursively visit sublists, do same stuff */
            lptemp = (struct b_list *)BlkD(elsrc->lslots[i], List);
            lpdest = ResolveList(lptemp);
            }
         else { 
            /* cset, integer constant, ... */
            parm = elsrc->lslots[i];
            }
         }
      }
   return lpdest;
   }
\end{verbatim}
The Unicon string scanning functions could used with a subset of the keywords that are pre-defined csets.  This implementation had to allow them to be used.  In the code above, the key word was identified by its characteristic \& at the beginning of its name.  Then the getkeyword function is called.  The following getkeyword function was added to the rmisc.r file in the runtime environment of the Unicon implementation to connect the keyword with its appropriate cset.
\begin{verbatim}
int getkeyword(char *s, dptr vp)
{
   if (strcmp(s, "&ascii") == 0) {
      Kascii(vp);
      return Succeeded;
      }
   if (strcmp(s, "&cset") == 0) {
      Kcset(vp);
      return Succeeded;
      }
   if (strcmp(s, "&digits") == 0) {
      Kdigits(vp);
      return Succeeded;
      }
   if (strcmp(s, "&lcase") == 0) {
      Klcase(vp);
      return Succeeded;
      }
   if (strcmp(s, "&letters") == 0) {
      Kletters(vp);
      return Succeeded;
      }
   if (strcmp(s, "&ucase") == 0) {
      Kucase(vp);
      return Succeeded;
      }
   return Failed;
   }
\end{verbatim}

\subsubsection{String and Pattern Concatenation Operators}
It was decided to have a consistent concatenation operator for string manipulation and pattern definitions as both result in the joining of a pair of strings into a larger string.  In the case of patterns the strings may not have been defined yet.  The existing string concatenation operator accepted only strings and csets, while Pattern concatenation accepts strings, c-sets and patterns.  Also, patterns and strings are different data types and string concatenation and pattern concatenation are handled in separate operations for these data types.  Therefore concatenation operator must identify whether a pattern is being used.  Then it has to send the appropriate data to the appropriate concatenation operation.

The following code identifies whether a pattern is being used with the concatenation operator.  If it is, then a pattern object will be returned; otherwise a string is returned.
\begin{verbatim}
   declare {
      int use_trap = 0;
      }

   if is:pattern(x) then {
      inline {
         use_trap = 1;
         }
      abstract {
         return pattern;
         }
      }
   else if is:pattern(y) then {
      inline {
         use_trap = 1;
         }
      abstract {
         return pattern;
         }
      }
   else {
      if !cnv:string(x) then runerr(103, x)
      if !cnv:string(y) then runerr(103, y)
      abstract {
         return string;
         }
      }
      
\end{verbatim}
If a pattern is identified in the above code, then the body of the function will know to return a pattern, and execute the following code, where it will setup the data required for pattern concatenation and call the pattern concatenation operation.
\begin{verbatim}
body {
   if (use_trap == 1) {
      union block *bp;
      /* convert strings to pattern blocks */
      struct b_pattern *lp;
      struct b_pattern *rp;
      struct b_pelem *pe;
      type_case x of {
         string:
            cnv_str_pattern(&x,&x);
         cset:
            cnv_cset_pattern(&x,&x);
         pattern: {
            }
         default:{
            runerr(127);
            }
         }
      type_case y of {
         string:
            cnv_str_pattern(&y,&y);
         cset:
			cnv_cset_pattern(&y,&y);
         pattern: {
            }
         default:{
            runerr(127);
            }
         }
      lp = (struct b_pattern *)BlkLoc(x);
      rp = (struct b_pattern *)BlkLoc(y);
      /* perform concatenation in patterns */
      pe = Concat(Copy((struct b_pelem *)lp->pe), 
            Copy((struct b_pelem *)rp->pe), rp->stck_size);
      bp = pattern_make_pelem(lp->stck_size + rp->stck_size,pe);
      return pattern(bp);
      }
      else {…
\end{verbatim}

\subsection{Revised Pattern Functions}
The pattern function names have been revised to be lexically more consistent with the Unicon language by revising the function definitions file, \texttt{fdef.h}, and the patterns source file \texttt{fxpattrn.ri} in Unicon source files.  The table below condenses the Table 2 to show the SNOBOL4 pattern functions with their corresponding Unicon functions for this implementation:  

\begin{table}[ht]
		\caption{Pattern Functions}
		\centering
		
		\begin{tabular}{|l|l|}
			\hline\hline
			SNOBOL4 & Unicon \\
			\hline
			LEN(n) & Len(n) \\
			SPAN(c) & Span(c)  \\
			BREAK(c) & Break(c) \\
			ANY(c) and NOTANY(c) & Any(c) \\
			TAB(n) and RTAB(n) & Tab(n) \\
			REM & Rem() \\
			POS(n) and RPOS(n) & Pos(n) \\
			FAIL & Back() \\
			FENCE & Fence() \\
			ABORT & Cancel() \\
			ARB & Arb() \\
			ARBNO(p) & Arbno(p) \\
			BAL & Bal() \\
			\hline
		\end{tabular}

\end{table}

\subsubsection{Index Related Functions}
The pattern cursor location representation in the pattern functions have been revised to match the Unicon index location of strings as shown in section 3.3.2 of this paper.  This was achieved by changing the Pos(n) function code to appear as follows:
\begin{verbatim}
function {1} Pos(position)
   abstract {
      return pattern;
   }
   body {
      union block *bp;
      /*
       * check if position is negative
       */
      if(position.vword.integr < 1) {
         /* change position to a positive value and use RPos */
         position.vword.integr = -position.vword.integr;
         ConvertPatternArgumentInt(position,bp,PC_RPos);
      } else {
         ConvertPatternArgumentInt(position,bp,PC_Pos);
      }
      return pattern(bp);
      }
end
\end{verbatim}
The position that is passed to the function is a \texttt{struct descrip} in the Unicon virtual machine that is defined to be an integer.  The details of the \texttt{struct descrip} can be found in Implementation of Icon and Unicon. \cite{JefferyImp}  The \texttt{if} statement in this function checks to see if the value of the descrip object is negative.  If it is negative then its value is changed to its complement the the ConvertPatternArgumentInt function is called while passing position, a block pattern and the PC\_RPos call as arguments.  If it is positive then position is not changed and the PC\_Pos argument is used instead while calling the ConvertPatternArgumentInt function.  A nearly identical changes ware made to Tab function.

The Rpos(n) and Rtab functions are now redundant, but are still available for the user who may be more comfortable with SNOBOL.  When using Rpos(n) and Rtab(n), the user has to be aware that they are based on the SNOBOL4 pattern matching cursor location system.

\section{Evaluation}
To evaluate the how successful this implementation of SNOBOL4 type patterns with Unicon's string scanning environment, a set of benchmark problems will be used to compare Gaikaiwari's pattern statements, the pattern statements in this implementation using both the anchored pattern match froom the string scanning environment and the non-anchored pattern matching environment, and equivalent Unicon string scanning functions.  The solutions for each problem will be evaluated for clarity, simplicity and functionality.  Clarity deals with the readability of the lines of code for each particular problem.  Can the user or programmer read the code without any ambiguity to what it is attempting to achieve.  Simplicity will be measured by the number of lines, words and characters required to achieve each benchmark problem.  Functionality of the example code will have to be consistent.  Each example will have to achieve the same result for each benchmark problem.  The benchmark problems are listed below:

\begin{itemize}
\item Decomposing phone numbers
\item Detecting words with double letters
\item Strings of the form \emph{$A^nB^nC^n$}
\item Number of times a word is used in a file
\end{itemize}

\subsection{Decomposing phone numbers}
For the purpose of Decomposing phone numbers in North America, each piece of example code will have to be able to identify the following:

\begin{enumerate}
\item area code is three digits with or without parentheses.
\item optional separator
\item trunk is three digits
\item optional separator
\item remaining four digits of the number
\end{enumerate}
area code, trunk, the remainder of the number.  The following example phone numbers should be recognizable:

\begin{enumerate}
\item 800-555-1212
\item 800 555 1212
\item 800.555.1212
\item (800) 555-1212
\item 1-800-555-1212
\item 1-(800) 555-1212
\end{enumerate}

An input fragment of "\texttt{Home: (800) 555-1212}" should result in identifying the area code as \texttt{800}, the trunk as \texttt{555}, the remainder of the number as being \texttt{1212}.

In the string scanning environment it can be achieved with the following code:
\begin{verbatim}
procedure digits(N)
   if N = 0 then return ""
   else return tab(any(&digits)) || digits(N - 1)
end

procedure main()
   line := "Uncle Sam: (800)555-1212 or uncle.sam@us.gov"
   sep := ""
   a := 0
   line ? {
      tab(upto(&digits))
      if line[&pos - 1] === "(" then {
         tab(&pos - 1)
         a := move(5)
         a ? areaCode := move(1) || digits(3) || tab(any(')'))
      } else {
         areaCode := digits(3)
         sep := tab(any(' -.'))
      } 
      prefix := digits(3)
      if sep === "" then sep := tab(any(' -.'))
      else tab(any(sep))
      number := digits(4)
   }
   if *areaCode == 5 then write(areaCode || trunk || sep || number)
   else write("(" || areaCode || ")" || trunk || sep || number)
end
\end{verbatim}
In this example, the phone number is found inductively.  It starts by skipping all the text up to the point where the digits begin, then it starts extracting each section of digits.  The first being for the area code; the second for the trunk; then identifying the character for the separation between the trunk and the remainder of the number; and finally the remainder of the number.  This requires more coding than the other options described below, and will give erroneous answers if the length of the area code or trunk is not three characters in length.  A couple more lines of code and the length of each part of the phone number can be defined.

In the pattern matching environment as implemented by Gaikaiwari, the problem can be resolved with the following code:
\begin{verbatim}
procedure main()
   line := "Uncle Sam: (800)555-1212 or uncle.sam@us.gov"
   threedigit := PAny(&digits) && PAny(&digits) && PAny(&digits)
   fourdigit := threedigit && PAny(&digits)
   area := ("(" && threedigit && ")" )
   pattern := (threedigit => areaCode && PAny(' -.') => sep
         && threedigit => trunk && `sep`
         && fourdigit => number)
      .| (area => areaCode && threedigit => trunk
         && PAny(' -.') => sep && fourdigit => number)
   line ?? pattern
   if *areaCode > 3 then write(areaCode || trunk || sep || number) 
   else write(areaCode || sep || trunk || sep || number) 
end
\end{verbatim}

In this implementation of patterns the code would be as follows:
\begin{verbatim}
procedure main()
   line := "Uncle Sam: (800)555-1212 or uncle.sam@us.gov"
   threedigit := Any(&digits) || Any(&digits) || Any(&digits)
   fourdigit := threedigit || Any(&digits)
   area := ( "(" || threedigit || ")" )
   pattern := ((threedigit => areaCode) || (Any(' -.') => sep) 
         || (threedigit => trunk) || `sep` 
         || (fourdigit => number))
      .| ((area => areaCode) || (threedigit => trunk) 
         || (Any(' -.') => sep) || (fourdigit => number))
   line ?? pattern
   if *areaCode > 3 then write(areaCode || trunk || sep || number) 
   else write(areaCode || sep || trunk || sep || number)
end
\end{verbatim}
In both of the pattern matching examples, the pattern is defined near the beginning of the code and allows the phone number to be found deductively. Although there is greater use of the parentheses for the assignment notation, it is lexically more consistent with Unicon and easier to read as a result.  

When using patterns within the string scanning environment it can be achieved with the following code:
\begin{verbatim}
procedure main()
   out := &output
   line := "Uncle Sam: (800)555-1212 or uncle.sam@us.gov"
   threedigit := Any(&digits) || Any(&digits) || Any(&digits)
   fourdigit := threedigit || Any(&digits)
   area := ("(" || threedigit || ")" )
   pattern := (Arb() || (threedigit => areaCode) || (Any(' -.') => sep) || 
         (threedigit => trunk) || Any(`sep`) || (fourdigit => number)) 
      .| (Arb() || (area => areaCode) || (threedigit => trunk) || 
         (Any(' -.') => sep) || (fourdigit => number))
   line ? =pattern 
   if *areaCode > 3 then write(areaCode || trunk || sep || number)
   else write(areaCode || sep || trunk || sep || number)
end
\end{verbatim}
In this example the user is able to separate the phone number pattern out of the string scanning environment by defining it as a pattern and then using the tabmat function to call an anchored pattern match when it is needed.  In this option the phone number is also found deductively, allowing the user more flexibility in using the pattern and improving the readability of the string scanning function.

\begin{verbatim}
*** still looking for a functioning example ***
procedure digits(N)
   if N = 0 then return ""
   else return tab(any(&digits)) || digits(N - 1)
end

procedure main()
   line := "Uncle Sam: (800)555-1212 or uncle.sam@us.gov"
   area := (Any("(") || `digits(3)` || ")" )
   pattern := (`tab(upto(&digits))` || (`digits(3)` => areaCode) || (Any(' -.') => sep) 
         || (`digits(3)` => trunk) || Any(`sep`) 
         || (`digits(4)` => number))
      .| ((area => areaCode) || (`digits(3)` => trunk) 
         || (Any(' -.') => sep) || (`digits(4)` => number))
   line ?? pattern
   if *areaCode == 5 then write(areaCode || trunk || sep || number)
   else write("(" || areaCode || ")" || trunk || sep || number) 
end
\end{verbatim}

\begin{table}[ht]
	\caption{Decomposing phone numbers}
	\centering
	\begin{tabular}{|l|l|l|l|l|}
		\hline\hline
		 & Lines & Words & Chars w/ ws & Chars wo/ ws\\
		\hline
		String scanning & 28 & 113 & 710 & 502 \\
		Gaikaiwari's Patterns & 10 & 92 & 599 & 460 \\
		Patterns & 10 & 93 & 610 & 470 \\
		Pattern in string scanning & 11 & 99 & 627 & 501 \\
		Unevaluated expression & 19 & 101 & 681 & 519 \\
		\hline
	\end{tabular}
\end{table}

\subsection{Detecting words with double letters}
In order to identify each word from a source file that has double letters, the procedure must be able to identify words like
\begin{itemize}
\item tooth
\item small
\item tomorrow
\end{itemize}

The string scanning example was used in\cite{Gaikaiwari2005} and is shown below.
\begin{verbatim}
procedure main()
   in := open("mtent12.txt", "r") | stop("open failed")
   out := open("mtentpatternOut.txt", "w")
   while line := read(in) do {
      line ? {
         while(tab(upto(&letters))) do {
            word := tab(many(&letters))
            word ? {
               while c := move(1) do {
                  if move(1) == c then {
                     write(out, word)
                     break;
                  }
               }
            }
         }
      }
   }
end
\end{verbatim}
It uses a nested call to the string scanning environment, the first to identify a word and the second to test to see if the word contains a double letter.  If it is successful then it outputs the word.

The next example provided in \cite{Gaikaiwari2005} shows how the problem can be solved by using Gaikaiwari's pattern data type and matching system.  
\begin{verbatim}
procedure main()
   in := open("mtent12.txt", "r") | stop("open failed")
   out := open("mtentpatternOut.txt, "w")
   double := PArbno(&letters) && PAny(&letters) $$ x && `x` && 
      (PSpan(&letters) .| "")
   every write(out, (line := !in) ?? double)
\end{verbatim}

The sample code below is the same as Gaikaiwari's, but it has been revised for this integration of Unicon patterns.
\begin{verbatim}
procedure main()
   in := open("mtent12.txt", "r") | stop("open failed")
   out := open("mtentpatternOut.txt", "w")
   double := Arbno(&letters) || (Any(&letters) => x) || `x` ||
      (Span(&letters) .| "")
   every write(out, (line := !in) ?? double)
end 
\end{verbatim}
In both cases the code is much shorter than the string scanning example.  This integration of Unicon patterns are simpler to read in part because the each concatenated pattern element is lexically identifiable with the \texttt{$||$} and the order of operations require the assignments and alternations to be defined within parentheses.  While in the Gaikaiwari patterns the aesthetic similarity of \texttt{\$\$} for concatenation and \texttt{\&\&} for immediate assignment can make them difficult to differentiate in complex patterns. 

In the following example the string scanning environment is initialized to identify each word, then each word is tested for any double letters, using a pattern sequence which is simpler than the combination of a while loop with a comparison as shown in the first example for this problem.
\begin{verbatim}
procedure main()
   in := open("mtent12.txt", "r") | stop("open failed")
   out := open("mtentpatternOut.txt", "w")
   double := Arb() || (Any(&letters) => x) || `x`
   while line := read(in) do {
      line ? {
         while(tab(upto(&letters))) do {
            word := tab(many(&letters))
            if word ? =double then write(out, word)
         }
      }
   }
end 
\end{verbatim}


\begin{table}[ht]
	\caption{Detecting words with double letters}
	\centering
	\begin{tabular}{|l|l|l|l|l|}
		\hline\hline
		 & Lines & Words & Chars w/ ws & Chars wo/ ws\\
		\hline
		String scanning & 18 & 53 & 470 & 250 \\
		Gaikaiwari's Patterns & 6 & 34 & 245 & 205 \\
		Unicon Patterns & 6 & 34 & 250 & 205 \\
		Pattern and string scanning & 13 & 48 & 373 & 256 \\
		\hline
	\end{tabular}
\end{table}
The pattern examples had the fewest number of lines, words and characters used.  When a pattern match was performed using the tabmat operator in the string scanning environment, it was easier to read and resulted in using fewer lines, words and characters as compared with using the string scanning environment alone.  For novice users of Unicon, this last example would be the easiest to understand.

\subsection{Strings of the form \emph{$A^nB^nC^n$}}
The third benchmark problem is the common language that cannot be parsed by a CFG grammar as was shown in \cite{Gaikaiwari2005}.  The programs return " accepted" when the string of characters containing "a"s, "b"s and "c"s is in the form of $a^nb^nc^n$ and return " rejected" when any other string is provided.

The string scanning example shown below is from \cite{Gaikaiwari2005} and \cite{Griswold1975}.  It is able to resolve the problem with 12 lines of code.
\begin{verbatim}
procedure ABC(s)
   suspend =s | (="a" || ABC("b" || s) || ="c")
end

procedure main()
   while write(line := read()) do
      if line ? {
         ABC("") & pos(0)
      } 
      then write(" accepted")
      else write(" rejected")
end
\end{verbatim}
The program defines a procedure ABC which is called in a string scanning environment to see if it contains the form $a^nb^nc^n$ and no other characters following.  Defining a procedure to test for a pattern is a common way to handle patterns when the pattern data type is not available.

Below is the example code Gaikaiwari provided to solve this problem using his implementation of patterns.  
\begin{verbatim}
procedure test(a, b, c)
   return ((a - 1) = (b - a)) & ((a - 1) = (c - b))
end

procedure main()
   pattern := PPos(1) && PSpan("a") && .$ a && PSpan("b") && .$ b && 
         PSpan("c") && .$ c && PRpos(0) && `test(a, b, c)`
   while write(line := read()) do {
      if(line ?? pattern) 
         then write(" accepted")
      else write(" rejected")
   }
end
\end{verbatim}
A test procedure was used to determine if the number of A's, B's and C's are equal.  This test was called at the end of the pattern definition causing the pattern succeed when they were all equal and fail when they were not.

The following example is another example how this problem can be solved; this time for the this implementation of patterns.
\begin{verbatim}
procedure main()
   pattern := Pos(1) || Span("a") || .> a || Span("b") || .> b || 
         Span("c") || .> c
   while write(line := read()) do {
      if(line ?? pattern) then {
         if (a - 1 == b - a & a - 1 == c - b) then write(" accepted")
         else write(" rejected")
      }
   }
end
\end{verbatim}
This example defines a pattern that defines the cursor location of for the end of a, b and c respectively.  Then tests those values to see if they are a mathematical match for the language.  The grammar requires the index location assignments to be made as a concatenation to an element in the pattern.  Again the \texttt{\&\&} operator for concatenation can be hard to distinguish while reading a pattern definition.

The following example uses the pattern matching environment within the string scanning environment and is able to resolve the problem with 9 lines of code.
\begin{verbatim}
procedure main()
   pattern := Pos(1) || Span("a") || .> a || Span("b") || .> b ||
         Span("c") || .> c 
   while write(line := read()) do
      line ? {
         =pattern
         if (a - 1 == b - a & a - 1 == c - b) then write(" accepted")
         else write(" rejected")
      }
end
\end{verbatim}
This example also defines a pattern that defines the cursor location of for the end of a, b and c respectively.  Then tests those values to see if they mathematically match for the language.

\begin{table}[ht]
	\caption{Strings of the form \emph{$A^nB^nC^n$}}
	\centering
	\begin{tabular}{|l|l|l|l|l|}
		\hline\hline
		 & Lines & Words & Chars w/ ws & Chars wo/ ws\\
		\hline
		String scanning & 12 & 35 & 226 & 162 \\
		Gaikaiwari's Patterns & 12 & 64 & 349 & 253 \\
		Unicon Patterns & 9 & 56 & 290 & 195 \\
		Pattern and string scanning & 9 & 53 & 275 & 185 \\
		Unevaluated expression & 19 & 101 & 681 & 519 \\
		\hline
	\end{tabular}
\end{table}

\subsection{Number of times a word is used}
To count the number of times a word is used in a block of text you need the algorithm to count every time the word is used and not when the word is a part of some other word.  Such as counting the number of times the word \texttt{the} is used, counting every \texttt{they, them, there} and so forth would not get the desired result.  So the algorithm must be refined enough to recognize the difference.

The following sample code solves this problem using the string scanning environment by examining blocks of letters and testing to see if the block of text matches the testword.
\begin{verbatim}
procedure main(args)
   in := open("test.txt", "r") | stop("open failed")
   testword := read()
   count := 0
   while line := read(in) do {
      line ? {
         while(tab(upto(&letters))) do {
            word := tab(many(&letters))
            if word === testword then count +:= 1
         }
      }
   }
   write(count)
end
\end{verbatim}

The following pattern matching examples show how they would appear in Gaikaiwari's and the current Unicon implementation respectively.
\begin{verbatim}
procedure main(args)
   in := open("test.txt", "r") | stop("open failed")
   word := read()
   pattern := PNotAny(&letters) && word && PNotAny(&letters)
   count := 0
   every w := !in ?? pattern do count +:= 1
   write(count)
end
\end{verbatim}

\begin{verbatim}
procedure main(args)
   in := open("test.txt", "r") | stop("open failed")
   word := read()
   pattern := Any(~&letters) || word || Any(~&letters)
   count := 0
   every w := !in ?? pattern do count +:= 1
   write(count)
end
\end{verbatim}
Both are are the same solution to the problem.  There are slight gains in typing in the second is a result of not having to use the \texttt{PNotAny()} function as the same result can be achieved with the \texttt{Any()} function while using the \texttt{~} before the cset.  This also improve the readability of code.

Finally, the following code resolves the problem using pattern matching from the string scanning environment.
\begin{verbatim}
procedure main(args)
   in := open("test.txt", "r") | stop("open failed")
   testword := read()
   pattern := Arb() || Any(~&letters) || testword || Any(~&letters)
   count := 0
   every line := !in do {
      line ? {
         while =pattern do count +:= 1
      }
   }
   write(count)
end
\end{verbatim}
In this example the pattern begins with an \texttt{Arb()} element.  Since the pattern match is carried out in the anchored mode, matching some arbitrary junk before the word is match is necessary otherwise the matching operation will not make the match unless the word starts at the current cursor location.  This can cause the pattern match to get hung up in an endless loop.

\begin{table}[ht]
	\caption{Number of times a word occurs in a file}
	\centering
	\begin{tabular}{|l|l|l|l|l|}
		\hline\hline
		 & Lines & Words & Chars w/ ws & Chars wo/ ws\\
		\hline
		String scanning & 14 & 43 & 330 & 216 \\
		Gaikaiwari's Patterns & 7 & 34 & 230 & 179 \\
		Unicon Patterns & 7 & 34 & 224 & 173 \\
		Pattern and string scanning & 12 & 43 & 279 & 206 \\
		Unevaluated expression & 19 & 101 & 681 & 519 \\
		\hline
	\end{tabular}
\end{table}


\section{Conclusions}
The integration of Gaikaiwari's pattern matching environment and the Unicon string scanning environment resulted in allowing users to utilize the pattern matching facilities from a string scanning environment, utilize the string scanning functions from the pattern matching environment, reduced the pattern matching functions by removing redundant functions, and made the pattern matching lexically harmonious with the Unicon language.

In each of the benchmark problems it was shown that this implementation of pattern matching in Unicon was easier to read than the previous implementation of pattern matching.  Clarity was improved with a lexically consistent pattern concatenation operator, lexically consistent lexemes for the pattern assignment operators and more concise lexemes for the pattern functions.  Using patterns within the string scanning environment resulted in code that was much easier to understand.

The pattern examples for each of the benchmark problems resulted in the shortest most concise code for the problem.  This implementation of patterns did not produce significantly improved code lengths as compared to Gaikaiwari's implementation, but it still produced a significant improvement over the string scanning environment of Unicon.

Overall this implementation of pattern matching in how it was integrated with the current string scanning environment is an improvement over Gaikaiwari's implementation, as it is more consistent lexically with the Unicon language.  Also, implementing patterns with Unicon improves the functionality of the language by allowing the user to solve complex string analysis problems with more options and less code than the current string scanning environment alone.

\section{Future Work}
Although the pattern matching and string scanning have been integrated, there are areas that need improvement.  Currently the string scanning functions can be called using the unevaluated expression, ideally they should be called in the same manner as pattern matching calls.  To achieve this a restructuring of the two systems where they are using the same set of string analysis functions.  A pattern matches are performed deductively where the pattern is pre-defined while the string scanning is performed inductively with each function is used consecutively.

It does not appear that nested pattern calls are currently supported.

Regular expressions


\newpage
\appendix
\section{\\Appendix A: Pattern Facilities Language Reference} \label{App:AppendixA}
\subsection{Pattern Variables}
\textbf{variable} \\
signifies a static variable\\
\noindent\rule{12cm}{0.4pt}
 
\noindent\textbf{`variable`} \\
signifies an unevaluated variable in a pattern\\

\subsection{Pattern Operators}
\noindent\textbf{pattern1 $\vert\vert$	pattern2} \hfill \textbf{pattern concatenation}\\
pattern concatenation operator produces a new pattern containing the left operand followed the right operand.\\
\noindent\rule{12cm}{0.4pt}

\noindent\textbf{pattern1 .$\vert$ pattern2} \hfill \textbf{pattern alteration}\\
pattern alteration operator produces a pattern containing either the left operand or the right operand.\\
\noindent\rule{12cm}{0.1pt}

\noindent\textbf{substring -$>$ variable} \hfill\textbf{conditional assignment}\\
assigns the substring on the left to the variable on the right if the pattern match is successful.\\
\noindent\rule{12cm}{0.1pt}

\noindent\textbf{result $=>$ variable} \hfill\textbf{immediate assignment}\\
assigns the immediate result on the left to a variable on the right within a pattern.\\
\noindent\rule{12cm}{0.1pt}

\noindent\textbf{.$>$ variable} \hfill\textbf{cursor position assignment}\\
assigns the cursor position of the string to a variable on the right within a pattern.\\
\noindent\rule{12cm}{0.1pt}

\noindent\textbf{string ?? pattern} \hfill\textbf{comparison operator}\\
compares the string on the left to see if there are any matches of the pattern on the right in the un-anchored mode.\\

\noindent\textbf{=pattern} \hfill\textbf{comparison operator}\\
compares the current string in the string scanning enviornment to see if there are is match of the pattern on the right in the anchored mode.\\

\subsection{Pattern Built-In Functions}
\noindent\textbf{Any(s)} \hfill\textbf{match any}\\
matches any single character contained in s appearing in the subject string.\\
\noindent\rule{12cm}{0.1pt}

\noindent\textbf{Arb()} \hfill\textbf{arbitrary pattern}\\
matches zero or more characters in the subject string.\\
\noindent\rule{12cm}{0.1pt}

\noindent\textbf{Arbno(p)} \hfill\textbf{repetitive arbitrary pattern}\\
matches repetitive sequences of p in the subject string.\\
\noindent\rule{12cm}{0.1pt}

\noindent\textbf{Bal()} \hfill\textbf{balanced parentheses}\\
matches the shortest non-null string which parentheses are balanced in the subject string.\\
\noindent\rule{12cm}{0.1pt}

\noindent\textbf{Break(s)} \hfill\textbf{pattern break}\\
matches any characters in the subject string up to but not including any of the characters in s.\\
\noindent\rule{12cm}{0.1pt}

\noindent\textbf{Breakx(s)} \hfill\textbf{extended pattern break}\\
matches any characters up to any of the subject characters in s, and will search beyond the break position for a possible larger match.\\
\noindent\rule{12cm}{0.1pt}

\noindent\textbf{Cancel()} \hfill\textbf{pattern cancel}\\
causes an immediate failure of the entire pattern match.\\
\noindent\rule{12cm}{0.1pt}

\noindent\textbf{Back()} \hfill\textbf{pattern back}\\
signals a failure in the current portion of the pattern match and sends an instruction to go back and try a different alternative.\\
\noindent\rule{12cm}{0.1pt}

\noindent\textbf{Fence()} \hfill\textbf{pattern fence}\\
signals a failure in the current portion of the pattern match if it is trying to backing up to try other alternatives.\\
\noindent\rule{12cm}{0.1pt}

\noindent\textbf{Len(n)} \hfill\textbf{match fixed-length string}\\
matches a string of a length of n characters in the subject string.  It fails if n is greater than the number of characters remaining in the subject string.\\
\noindent\rule{12cm}{0.1pt}

\noindent\textbf{Pos(n)} \hfill\textbf{cursor position}\\
sets the cursor or index position of the subject string to the position n according the Unicon index system shown bellow:
\begin{verbatim}
                   -6  -5  -4  -3  -2  -1  0
                   | U | n | i | c | o | n |
                   1   2   3   4   5   6   7
\end{verbatim}
\noindent\rule{12cm}{0.1pt}

\noindent\textbf{Tab(n)} \hfill\textbf{pattern tab}\\
matches any characters from the current cursor or index position up to the specified position of the subject string. Tab uses the Unicon index system shown in Pos and position n must be to the right of the current position.\\
\noindent\rule{12cm}{0.1pt}

\noindent\textbf{Rem()} \hfill\textbf{remainder pattern}\\
matches the remainder of the subject string.\\
\noindent\rule{12cm}{0.1pt}

\noindent\textbf{Span(s)} \hfill\textbf{pattern span}\\
matches one or more characters from the subject string that are contained in s.  It must match at least one character.\\
\noindent\rule{12cm}{0.1pt}

\noindent\textbf{Rpos(n)} \hfill\textbf{reverse cursor position}\\
sets the cursor or index position of the subject string to the position n according the SNOBOL4 index system shown bellow:
\begin{verbatim}
                   6   5   4   3   2   1   0
                   | S | N | O | B | O | L |
                   1   2   3   4   5   6   7
\end{verbatim}
\noindent\rule{12cm}{0.1pt}

\noindent\textbf{Rtab(n)} \hfill\textbf{pattern reverse tab}\\
matches any characters from the current cursor or index position up to the specified position of the subject string. Rtab uses the SNOBOL4 index system shown in Rpos and position n must be to the right of the current position.\\


\newpage
\bibliography{Patterns}
\bibliographystyle{ieeetr}

\end{document}
